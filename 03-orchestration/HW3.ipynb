{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "The goal of this homework is to create a simple training pipeline, use mlflow to track experiments and register best model, but use Mage for it.\n",
    "\n",
    "We'll use [the same NYC taxi dataset](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page), the **Yellow** taxi data for March, 2023. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1. Select the Tool\n",
    "\n",
    "You can use the same tool you used when completing the module,\n",
    "or choose a different one for your homework."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Mage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2. Version\n",
    "\n",
    "What's the version of the orchestrator? "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "0.9.76"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3. Creating a pipeline\n",
    "\n",
    "Let's read the March 2023 Yellow taxi trips data.\n",
    "\n",
    "How many records did we load? \n",
    "\n",
    "- 3,003,766\n",
    "- 3,203,766\n",
    "- 3,403,766    <--\n",
    "- 3,603,766\n",
    "\n",
    "(Include a print statement in your code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T01:42:22.791588Z",
     "iopub.status.busy": "2025-06-09T01:42:22.791223Z",
     "iopub.status.idle": "2025-06-09T01:42:22.795064Z",
     "shell.execute_reply": "2025-06-09T01:42:22.794268Z",
     "shell.execute_reply.started": "2025-06-09T01:42:22.791563Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T01:42:22.796911Z",
     "iopub.status.busy": "2025-06-09T01:42:22.796631Z",
     "iopub.status.idle": "2025-06-09T01:42:25.335432Z",
     "shell.execute_reply": "2025-06-09T01:42:25.335077Z",
     "shell.execute_reply.started": "2025-06-09T01:42:22.796890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3,403,766 records\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-03.parquet')\n",
    "print(f\"Loaded {len(df):,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4. Data preparation\n",
    "\n",
    "Let's continue with pipeline creation.\n",
    "\n",
    "We will use the same logic for preparing the data we used previously. \n",
    "\n",
    "This is what we used (adjusted for yellow dataset):\n",
    "\n",
    "```python\n",
    "def read_dataframe(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df.duration = df.duration.dt.total_seconds() / 60\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df\n",
    "```\n",
    "\n",
    "Let's apply to the data we loaded in question 3. \n",
    "\n",
    "What's the size of the result? \n",
    "\n",
    "- 2,903,766\n",
    "- 3,103,766\n",
    "- 3,316,216    <---\n",
    "- 3,503,766"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T01:42:25.336008Z",
     "iopub.status.busy": "2025-06-09T01:42:25.335925Z",
     "iopub.status.idle": "2025-06-09T01:42:25.338985Z",
     "shell.execute_reply": "2025-06-09T01:42:25.338575Z",
     "shell.execute_reply.started": "2025-06-09T01:42:25.335999Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_dataframe(df):\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df.duration = df.duration.dt.total_seconds() / 60\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T01:42:25.341252Z",
     "iopub.status.busy": "2025-06-09T01:42:25.340990Z",
     "iopub.status.idle": "2025-06-09T01:42:26.294336Z",
     "shell.execute_reply": "2025-06-09T01:42:26.294036Z",
     "shell.execute_reply.started": "2025-06-09T01:42:25.341241Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kd/8px7m6vn687gphwqxs42_dcm0000gp/T/ipykernel_56929/4014942768.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[categorical] = df[categorical].astype(str)\n"
     ]
    }
   ],
   "source": [
    "data = prepare_dataframe(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T01:42:26.294921Z",
     "iopub.status.busy": "2025-06-09T01:42:26.294823Z",
     "iopub.status.idle": "2025-06-09T01:42:26.298504Z",
     "shell.execute_reply": "2025-06-09T01:42:26.297811Z",
     "shell.execute_reply.started": "2025-06-09T01:42:26.294912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3,316,216 records\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loaded {len(data):,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T00:59:53.718915Z",
     "iopub.status.busy": "2025-06-09T00:59:53.718551Z",
     "iopub.status.idle": "2025-06-09T00:59:53.724344Z",
     "shell.execute_reply": "2025-06-09T00:59:53.723147Z",
     "shell.execute_reply.started": "2025-06-09T00:59:53.718891Z"
    }
   },
   "source": [
    "## Question 5. Train a model\n",
    "\n",
    "We will now train a linear regression model using the same code as in homework 1.\n",
    "\n",
    "* Fit a dict vectorizer.\n",
    "* Train a linear regression with default parameters.\n",
    "* Use pick up and drop off locations separately, don't create a combination feature.\n",
    "\n",
    "Let's now use it in the pipeline. We will need to create another transformation block, and return both the dict vectorizer and the model.\n",
    "\n",
    "What's the intercept of the model? \n",
    "\n",
    "Hint: print the `intercept_` field in the code block\n",
    "\n",
    "- 21.77\n",
    "- 24.77      <--\n",
    "- 27.77\n",
    "- 31.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T01:42:26.299637Z",
     "iopub.status.busy": "2025-06-09T01:42:26.299520Z",
     "iopub.status.idle": "2025-06-09T01:42:26.303120Z",
     "shell.execute_reply": "2025-06-09T01:42:26.302522Z",
     "shell.execute_reply.started": "2025-06-09T01:42:26.299627Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T01:42:26.304346Z",
     "iopub.status.busy": "2025-06-09T01:42:26.303738Z",
     "iopub.status.idle": "2025-06-09T01:42:26.322376Z",
     "shell.execute_reply": "2025-06-09T01:42:26.321965Z",
     "shell.execute_reply.started": "2025-06-09T01:42:26.304236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/2', creation_time=1749432753134, experiment_id='2', last_update_time=1749432753134, lifecycle_stage='active', name='homework3', tags={}>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"homework3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T01:42:26.323091Z",
     "iopub.status.busy": "2025-06-09T01:42:26.322924Z",
     "iopub.status.idle": "2025-06-09T01:42:33.987891Z",
     "shell.execute_reply": "2025-06-09T01:42:33.987456Z",
     "shell.execute_reply.started": "2025-06-09T01:42:26.323078Z"
    }
   },
   "outputs": [],
   "source": [
    "data['target'] = data['duration']\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "def df_to_dict(df):\n",
    "    return df[categorical].to_dict(orient='records')\n",
    "train_df, val_df = train_test_split(data, test_size=0.2, random_state=42)\n",
    "dv = DictVectorizer()\n",
    "X_train = dv.fit_transform(df_to_dict(train_df))\n",
    "X_val = dv.transform(df_to_dict(val_df))\n",
    "target = 'duration'\n",
    "y_train = train_df[target].values\n",
    "y_val = val_df[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T01:42:33.989379Z",
     "iopub.status.busy": "2025-06-09T01:42:33.989265Z",
     "iopub.status.idle": "2025-06-09T01:42:56.070036Z",
     "shell.execute_reply": "2025-06-09T01:42:56.069738Z",
     "shell.execute_reply.started": "2025-06-09T01:42:33.989370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run dashing-crow-418 at: http://127.0.0.1:5000/#/experiments/2/runs/be0ae907142e40cbb088c344048cd82d\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/2\n",
      "y-Intercept is: 24.75145745943043\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_val)\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_param(\"model_type\", \"LinearRegression\")\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=lr,\n",
    "        artifact_path=\"models\",\n",
    "        input_example=X_val[:1],\n",
    "        signature=mlflow.models.signature.infer_signature(X_val, y_pred)\n",
    "    )\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_train)\n",
    "print('y-Intercept is:', lr.intercept_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6. Register the model \n",
    "\n",
    "The model is trained, so let's save it with MLFlow.\n",
    "\n",
    "Find the logged model, and find MLModel file. What's the size of the model? (`model_size_bytes` field):\n",
    "\n",
    "* 14,534\n",
    "* 9,534\n",
    "* 4,534   <--\n",
    "* 1,534"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T02:18:28.937427Z",
     "iopub.status.busy": "2025-06-09T02:18:28.936958Z",
     "iopub.status.idle": "2025-06-09T02:18:32.873919Z",
     "shell.execute_reply": "2025-06-09T02:18:32.873587Z",
     "shell.execute_reply.started": "2025-06-09T02:18:28.937401Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/08 20:18:28 WARNING mlflow.utils.autologging_utils: MLflow sklearn autologging is known to be compatible with 0.24.1 <= scikit-learn <= 1.6.1, but the installed version is 1.7.0. If you encounter errors during autologging, try upgrading / downgrading scikit-learn to a compatible version, or try upgrading MLflow.\n",
      "\u001b[31m2025/06/08 20:18:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Successfully registered model 'linear-reg-model'.\n",
      "2025/06/08 20:18:32 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: linear-reg-model, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run caring-dove-859 at: http://127.0.0.1:5000/#/experiments/3/runs/533df48171b443e09e517fa84807e85a\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'linear-reg-model'.\n"
     ]
    }
   ],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "MLFLOW_TRACKING_URI = \"sqlite:///home/mlflow/mlflow.db\"\n",
    "mlflow.set_experiment(\"LR-model\")   \n",
    "mlflow.sklearn.autolog()\n",
    "    \n",
    "with mlflow.start_run() as run:\n",
    "\n",
    "    dv = df\n",
    "    #Save and log the artifact (dict vectorizer)\n",
    "    with open(\"models/preprocessor.b\", \"wb\") as f_out:\n",
    "        pickle.dump(dv, f_out)\n",
    "\n",
    "    mlflow.log_artifact(\"models/preprocessor.b\", artifact_path=\"preprocessor\")\n",
    "       \n",
    "    # Log the linear regression model and register as version 1\n",
    "    mlflow.sklearn.log_model(\n",
    "            sk_model=lr,\n",
    "            artifact_path=\"sklearn-model\",\n",
    "            registered_model_name=\"linear-reg-model\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
